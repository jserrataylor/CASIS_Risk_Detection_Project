{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZTAsyWenoagResJvu07xM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jserrataylor/ed_project/blob/main/CASIS_Risk_Detection_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASIS Risk Detection Project"
      ],
      "metadata": {
        "id": "X4OYjj2AfMth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.stats import uniform, randint\n",
        "import joblib  # Importar joblib para guardar los modelos\n",
        "\n",
        "# Carga de datos\n",
        "data_url = 'https://raw.githubusercontent.com/jserrataylor/CASIS/main/casis_datasets.csv'\n",
        "df = pd.read_csv(data_url)\n",
        "\n",
        "# Selección de columnas relevantes\n",
        "columns_to_keep = [\n",
        "    'Tengodificultadesconelsueño',\n",
        "    'Consideréseriamentelastimaraotrapersona',\n",
        "    'Sentílanecesidaddereducirelusodebebidasalcóholicasyodrogas',\n",
        "    'Asistíaconsejeríaopsicoterapiaporasuntosrelacionadosconmisalud',\n",
        "    'Hetenidoataquesdepánicoepisodiosdeansiedadseveraqueduranalreded',\n",
        "    'Tengopreocupacionesrelacionadasamialimentacióndietasnosaludable',\n",
        "    'Hetenidocontactossexualesuotrasexperienciasdeíndolesexualsindes',\n",
        "    'CASIC'\n",
        "]\n",
        "df = df[columns_to_keep]\n",
        "\n",
        "# Limpieza de datos\n",
        "df = df.apply(pd.to_numeric, errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "df['CASIC'] = df['CASIC'].astype(int)\n",
        "\n",
        "# Preparación de datos para SMOTE\n",
        "X = df.drop('CASIC', axis=1)\n",
        "y = df['CASIC']\n",
        "smote = SMOTE()\n",
        "X_sm, y_sm = smote.fit_resample(X, y)\n",
        "\n",
        "# División de los datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=42)\n",
        "\n",
        "# Configuración de RandomizedSearchCV para cada modelo\n",
        "modelos = {\n",
        "    'Logistic Regression': (LogisticRegression(), {'C': uniform(0.01, 100), 'solver': ['liblinear', 'saga'], 'penalty': ['l1', 'l2']}),\n",
        "    'SVM': (SVC(), {'C': uniform(0.1, 100), 'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma': ['scale', 'auto', 0.1, 0.01, 0.001], 'degree': randint(2, 5)}),\n",
        "    'Random Forest': (RandomForestClassifier(), {'n_estimators': randint(100, 400), 'max_depth': [10, 20, 30, None], 'min_samples_split': randint(2, 11), 'min_samples_leaf': randint(1, 5)}),\n",
        "    'KNN': (KNeighborsClassifier(), {'n_neighbors': randint(3, 11), 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']})\n",
        "}\n",
        "\n",
        "# Entrenar y evaluar cada modelo con configuraciones por defecto\n",
        "initial_results = {}\n",
        "for name, (model, _) in modelos.items():\n",
        "    model.fit(X_train, y_train)  # Entrenamiento con configuración por defecto\n",
        "    y_pred_initial = model.predict(X_test)\n",
        "    initial_results[name] = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred_initial),\n",
        "        \"Precision\": precision_score(y_test, y_pred_initial),\n",
        "        \"Recall\": recall_score(y_test, y_pred_initial),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred_initial)\n",
        "    }\n",
        "\n",
        "# Optimización de modelos usando RandomizedSearchCV\n",
        "optimized_results = {}\n",
        "for name, (model, params) in modelos.items():\n",
        "    random_search = RandomizedSearchCV(model, params, n_iter=100, cv=5, scoring='recall', verbose=1, random_state=42)\n",
        "    random_search.fit(X_train, y_train)\n",
        "    best_model = random_search.best_estimator_\n",
        "    y_pred_optimized = best_model.predict(X_test)\n",
        "    optimized_results[name] = {\n",
        "        \"Best Parameters\": random_search.best_params_,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred_optimized),\n",
        "        \"Precision\": precision_score(y_test, y_pred_optimized),\n",
        "        \"Recall\": recall_score(y_test, y_pred_optimized),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred_optimized)\n",
        "    }\n",
        "    # Guardar el modelo optimizado\n",
        "    joblib.dump(best_model, f'{name}_optimized_model.pkl')\n",
        "\n",
        "# Imprimir resultados antes y después de la optimización\n",
        "for model_name in modelos.keys():\n",
        "    print(f\"Resultados iniciales para {model_name}:\")\n",
        "    for metric, value in initial_results[model_name].items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "    print(\"\\nResultados optimizados para {model_name}:\")\n",
        "    for metric, value in optimized_results[model_name].items():\n",
        "        if metric == \"Best Parameters\":\n",
        "            print(f\"{metric}: {value}\")\n",
        "        else:\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "0xtSksNE2Qe-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}